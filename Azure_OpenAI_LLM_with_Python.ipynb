{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMOsk1tBU0V/pjSQE3LHsnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MFB-Napier/LangChain-OpenAI-and-LLAMA-2-LLM/blob/master/Azure_OpenAI_LLM_with_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Set up the environment**"
      ],
      "metadata": {
        "id": "ANjLoUuosit-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QvYeleC9b8Tz",
        "outputId": "8a76b7c0-c34a-4510-808e-e759ea0123c8"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import AzureOpenAI\n",
        "import os\n",
        "from datetime import datetime"
      ],
      "metadata": {
        "id": "dbyfqj7ldRzT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Initialize the Azure OpenAI Client**"
      ],
      "metadata": {
        "id": "8vzbEAObsthP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "endpoint=userdata.get('azure_endpoint')\n",
        "key=userdata.get('api_key')\n",
        "version=userdata.get('api_version')\n",
        "\n",
        "client = AzureOpenAI(\n",
        "    azure_endpoint = endpoint,  # Replace with your Azure OpenAI endpoint\n",
        "    api_key = key,  # Replace with your API key\n",
        "    api_version = version\n",
        ")"
      ],
      "metadata": {
        "id": "CP8lJ3AvdVrk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelo=userdata.get('model')"
      ],
      "metadata": {
        "id": "xxdqo9lefxJB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Create and format the PROMPT**"
      ],
      "metadata": {
        "id": "hk8m9SSfs3nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "message = [\n",
        "    {\"role\": \"system\", \"content\": \"You are an AI assistant that helps people find information.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Please tell me about Stanford University and California State University, Sacramento.\"}\n",
        "]\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "  model=modelo, # model = \"deployment_name\"\n",
        "  messages = message,\n",
        "  temperature=0.7,\n",
        "  max_tokens=800,\n",
        "  top_p=0.95,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=None\n",
        ")"
      ],
      "metadata": {
        "id": "yHSfG8JGdqbd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Send the PROMPT to the Model**"
      ],
      "metadata": {
        "id": "8XZrqWE-tCP9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = client.chat.completions.create(\n",
        "  model=modelo, # model = \"deployment_name\"\n",
        "  messages = message,\n",
        "  temperature=0.7,\n",
        "  max_tokens=800,\n",
        "  top_p=0.95,\n",
        "  frequency_penalty=0,\n",
        "  presence_penalty=0,\n",
        "  stop=None\n",
        ")"
      ],
      "metadata": {
        "id": "atBIgrazd-6j"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Print the Response**"
      ],
      "metadata": {
        "id": "BVXFOKLvtI4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime  # Make sure to include this import\n",
        "\n",
        "def print_formatted_response(completion):\n",
        "    # Print a header to separate each response\n",
        "    print(\"\\n--- Response Details ---\")\n",
        "\n",
        "    # Loop through each choice in the completion (typically there will be just one)\n",
        "    for choice in completion.choices:\n",
        "        # Print the response content\n",
        "        print(\"\\nContent:\")\n",
        "        print(choice.message.content)\n",
        "\n",
        "        # Print the finish reason\n",
        "        print(\"\\nFinish Reason:\", choice.finish_reason)\n",
        "\n",
        "        # Print the role of the message\n",
        "        print(\"\\nRole:\", choice.message.role)\n",
        "\n",
        "        # Print tool calls and function call if applicable\n",
        "        print(\"\\nFunction Call:\", choice.message.function_call)\n",
        "        if choice.message.tool_calls:\n",
        "            print(\"\\nTool Calls:\")\n",
        "            for tool_call in choice.message.tool_calls:\n",
        "                print(tool_call)\n",
        "\n",
        "        # Print content filter results\n",
        "        print(\"\\nContent Filter Results:\")\n",
        "        for key, value in choice.content_filter_results.items():\n",
        "            print(f\"{key.capitalize()}: Filtered={value['filtered']}, Severity={value['severity']}\")\n",
        "\n",
        "    # Print token usage information\n",
        "    print(\"\\nTokens Used:\", completion.usage.total_tokens)\n",
        "\n",
        "    # Print the model used\n",
        "    print(\"\\nModel Used:\", completion.model)\n",
        "\n",
        "    # Print the creation time\n",
        "    print(\"\\nCreated At:\", completion.created)\n",
        "\n",
        "    # Convert Unix timestamp to human-readable date and time\n",
        "    created_at = datetime.utcfromtimestamp(completion.created).strftime('%Y-%m-%d %H:%M:%S UTC')\n",
        "    print(\"\\nCreated At:\", created_at)\n",
        "\n",
        "# Print formatted response\n",
        "print_formatted_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQyDMZ1seWI5",
        "outputId": "0d4f1656-b4f1-4725-963f-c629f245ed46"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Response Details ---\n",
            "\n",
            "Content:\n",
            "Stanford University is a private research university located in Stanford, California. It was founded in 1885 by Leland Stanford and his wife, Jane Stanford, in memory of their son. Stanford is known for its prestigious academic programs, world-class faculty, and beautiful campus.\n",
            "\n",
            "Stanford offers undergraduate and graduate programs across a wide range of disciplines, including humanities, social sciences, natural sciences, engineering, business, and law. The university is particularly renowned for its programs in computer science, engineering, entrepreneurship, medicine, and the arts. Stanford is also affiliated with several research centers and institutes, contributing to its reputation as a leading institution for scientific research and innovation.\n",
            "\n",
            "California State University, Sacramento, commonly known as Sacramento State or CSUS, is a public university located in Sacramento, California. It was founded in 1947 as Sacramento State College and became part of the California State University system in 1960.\n",
            "\n",
            "Sacramento State offers a comprehensive range of undergraduate and graduate programs across various fields of study. The university is organized into eight colleges, including the College of Arts and Letters, College of Business Administration, College of Education, and College of Health and Human Services. Sacramento State is known for its strong programs in business, education, engineering, government, and healthcare.\n",
            "\n",
            "Both Stanford University and California State University, Sacramento, offer diverse academic opportunities and contribute to the educational landscape of California. However, it's important to note that Stanford is a private institution with a higher level of selectivity and resources, while Sacramento State is a public university with a larger student population and a more accessible admissions process.\n",
            "\n",
            "Finish Reason: stop\n",
            "\n",
            "Role: assistant\n",
            "\n",
            "Function Call: None\n",
            "\n",
            "Content Filter Results:\n",
            "Hate: Filtered=False, Severity=safe\n",
            "Self_harm: Filtered=False, Severity=safe\n",
            "Sexual: Filtered=False, Severity=safe\n",
            "Violence: Filtered=False, Severity=safe\n",
            "\n",
            "Tokens Used: 353\n",
            "\n",
            "Model Used: gpt-35-turbo-16k\n",
            "\n",
            "Created At: 1716418462\n",
            "\n",
            "Created At: 2024-05-22 22:54:22 UTC\n"
          ]
        }
      ]
    }
  ]
}